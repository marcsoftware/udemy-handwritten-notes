1
00:00:00,750 --> 00:00:03,400
Hello bloggers and welcome to this lecture.

2
00:00:03,480 --> 00:00:09,360
And this is just a really quick summary of everything that we've covered in this chapter and it's all

3
00:00:09,360 --> 00:00:15,420
based on student feedback and designed to help you get a few extra points in the exam.

4
00:00:15,420 --> 00:00:19,330
Starting off with a W S CLIA pudgy nation.

5
00:00:19,380 --> 00:00:27,240
Now if you're using the IWC CLIA and you see errors like timed out or errors relating to too many results

6
00:00:27,240 --> 00:00:34,260
being returned then it's likely that you have an issue relating to too many results being returned to

7
00:00:34,260 --> 00:00:40,860
your CLIA output and the way that you deal with that is you adjust the pageant portion of CLIA requests

8
00:00:41,190 --> 00:00:47,610
to avoid errors being generated by too many results and you don't need to remember this command for

9
00:00:47,610 --> 00:00:49,150
the exam.

10
00:00:49,170 --> 00:00:53,360
The main thing that you need to remember is that we are changing the page size.

11
00:00:53,430 --> 00:00:59,970
So just try and keep in mind that we're changing the page size to return fewer results per page.

12
00:00:59,970 --> 00:01:05,700
And when we do this the command line still retrieves the full list of results but it performs a greater

13
00:01:05,760 --> 00:01:12,320
number of API calls in the background and retrieves a smaller number of items with each call.

14
00:01:12,390 --> 00:01:19,100
And that's going to avoid you getting the errors generated by too many results in each API call.

15
00:01:19,110 --> 00:01:25,290
Moving on to the identity access management policy simulator and the policy simulator enables you to

16
00:01:25,290 --> 00:01:32,400
test identity access management permissions before you commit them into production so you can use the

17
00:01:32,400 --> 00:01:39,660
policy simulator to validate that the policy works as expected and you can also test policies attached

18
00:01:39,660 --> 00:01:41,060
to existing users.

19
00:01:41,190 --> 00:01:47,100
And that is really good for troubleshooting if you suspect that something within your NWS account is

20
00:01:47,100 --> 00:01:52,290
not working as expected and you suspect that it's something to do with an identity access management

21
00:01:52,290 --> 00:01:58,920
policy so you can just go into the simulator and test whether that action would be allowed by any policy

22
00:01:59,010 --> 00:02:04,800
attached to your user group or role and the simulator will tell you whether that action would be allowed

23
00:02:04,860 --> 00:02:05,370
or not.

24
00:02:08,300 --> 00:02:14,510
Just remember that you can use the excuse us delay Q If you need to postpone the delivery of new messages

25
00:02:14,840 --> 00:02:20,990
messages in your delay queue remain invisible for the duration of the delay period and it's zero by

26
00:02:20,990 --> 00:02:21,790
default.

27
00:02:21,920 --> 00:02:29,600
Up to 900 seconds or 15 minutes and you can use delay queues for large distributed applications which

28
00:02:29,600 --> 00:02:36,680
might need to introduce a delay in processing in order to avoid errors in the application and for managing

29
00:02:36,710 --> 00:02:38,780
large messages in rescuers.

30
00:02:38,780 --> 00:02:40,610
Just remember our exam tips.

31
00:02:40,620 --> 00:02:47,030
So if you have large messages up to 2 gig store them in S3 and in order to do that you're going to need

32
00:02:47,030 --> 00:02:55,220
to have an S3 Buckets and you'll also need to use the w w SDK for Java as well as the escudos extended

33
00:02:55,250 --> 00:02:57,740
client library for Java as well.

34
00:02:57,800 --> 00:03:05,060
And just remember you can't do this using the regular a SC ally or the management console or the escudos

35
00:03:05,140 --> 00:03:06,220
API.

36
00:03:06,290 --> 00:03:12,980
Moving on can easiest shards and just remember the Cooney says client library is running on your consumers

37
00:03:13,370 --> 00:03:19,280
and it's the easiest client library which creates a record processor for each Canisius shard which is

38
00:03:19,280 --> 00:03:21,380
being consumed by your instance.

39
00:03:21,560 --> 00:03:27,320
And when you increase the number of shots the carnitas client library will add more record processors

40
00:03:27,590 --> 00:03:28,610
on your consumers.

41
00:03:29,180 --> 00:03:35,450
And just remember that it's CPE utilization which should drive the quantity of consumer instances you

42
00:03:35,450 --> 00:03:39,050
have not the number of shards in your Canisius stream.

43
00:03:39,470 --> 00:03:44,970
So if you do increase the number of shards if you reach shard and increase the number of shards say

44
00:03:45,050 --> 00:03:51,050
from 4 to 8 then it is not required to increase the quantity of consumer instances.

45
00:03:51,050 --> 00:03:55,230
You should definitely base that on utilization not the number of shards.

46
00:03:55,340 --> 00:04:01,910
And finally it's best practice to use an auto scaling group and base scaling decisions on the CPE you

47
00:04:01,910 --> 00:04:04,370
load of your consumers.

48
00:04:04,570 --> 00:04:08,440
Moving on to lambda and the lambda concurrent executions limit.

49
00:04:09,160 --> 00:04:14,410
All you need to know for the exam is that a limit exists and you don't really need to remember the number.

50
00:04:14,440 --> 00:04:19,900
I just think it's helpful to know that it's a thousand concurrent executions per second and of course

51
00:04:19,900 --> 00:04:25,750
if you're running a service website a busy website like a cloud guru it's definitely likely that you're

52
00:04:25,750 --> 00:04:28,140
going to hit the limit at some point.

53
00:04:28,330 --> 00:04:33,520
And if you do hit the limit then you're going to start seeing invocations being rejected.

54
00:04:33,520 --> 00:04:39,400
So you will see lambda functions failing to be launched and new invocations of lambda functions being

55
00:04:39,400 --> 00:04:47,500
rejected and you are likely to see a 4 to 9 HDP status code and the remedy for this is just to request

56
00:04:47,830 --> 00:04:52,780
a limit raised from a w s support which you can do from the console.

57
00:04:52,780 --> 00:04:56,620
And there's also a reserved concurrency which you can apply.

58
00:04:56,680 --> 00:05:04,180
And this guarantees a set number of concurrent executions are always available to your critical functions

59
00:05:04,570 --> 00:05:11,650
so you can go in and set a reserve concurrency for example for 500 concurrent executions for a critical

60
00:05:11,650 --> 00:05:18,760
function and or guarantee that there's always 500 concurrent executions available to that function.

61
00:05:18,760 --> 00:05:25,690
Moving onto lambda versions and $ latest is always the last version of the code that you uploaded to

62
00:05:25,690 --> 00:05:32,980
lambda and you can use lambda versioning and aliases to point your applications to a specific version.

63
00:05:33,100 --> 00:05:39,340
If you don't want to use dollar latest for example if you had different versions of your code for development

64
00:05:39,610 --> 00:05:46,450
test and production environments you can set up versioning and aliases to point to those different versions

65
00:05:46,480 --> 00:05:47,490
of your code base.

66
00:05:48,160 --> 00:05:52,370
And here is an example of an alias for our production system.

67
00:05:52,420 --> 00:05:57,780
So the alias is called prod and it's in the form of an Amazon resource name.

68
00:05:57,880 --> 00:06:03,880
So that's what your applications would use if they want to refer to that prot alias version of our code.

69
00:06:04,020 --> 00:06:09,070
And if you want your applications to always use the latest version you would just use the IRS n with

70
00:06:09,180 --> 00:06:15,790
dollar latest at the end and finally just remember that if your application is using an alias instead

71
00:06:15,850 --> 00:06:22,760
of dollar latest then remember that it will not automatically use new code when you upload it.

72
00:06:22,780 --> 00:06:30,340
So for example if your application is pointing to the prod alias it's going to continue to use the version

73
00:06:30,340 --> 00:06:32,450
of Code referenced by the alias.

74
00:06:32,560 --> 00:06:38,350
Even when you upload new code into lambda so if you've uploaded new code into lambda and you're wondering

75
00:06:38,380 --> 00:06:44,350
why your application is still launching the old version of code it could well be that you're pointing

76
00:06:44,350 --> 00:06:48,960
to an alias rather than using the dollar latest version.

77
00:06:49,000 --> 00:06:53,290
Moving onto lambda and accessing resources in your private VPC.

78
00:06:53,290 --> 00:06:59,560
Just remember it's possible to enable lambda to access resources in your private VPC but it is not enabled

79
00:06:59,560 --> 00:07:00,520
by default.

80
00:07:00,520 --> 00:07:07,330
And in order to set this up you're going to need to provide VPC config information to the function in

81
00:07:07,330 --> 00:07:11,490
the form of a private subnet I.D. add a security group.

82
00:07:11,530 --> 00:07:19,150
And remember that lambda uses this VPC information to set up elastic network interfaces using an IP

83
00:07:19,150 --> 00:07:25,570
address from the private subnet slider range and then the security group allows your function to access

84
00:07:25,630 --> 00:07:28,050
the resources in your VPC.

85
00:07:28,060 --> 00:07:35,590
Moving all it to x ray high level configuration steps so x ray integrates with many w services like

86
00:07:35,590 --> 00:07:39,580
dynamo D.B. lambda API Gateway etc..

87
00:07:40,060 --> 00:07:45,750
So you really need the minimum amount of configuration in order to set these services up for x ray.

88
00:07:46,000 --> 00:07:53,200
However you can also instrument your own applications to send data into x ray and applications could

89
00:07:53,200 --> 00:08:00,730
be running on easy to an elastic beanstalk environments and also on your on premises systems located

90
00:08:00,730 --> 00:08:05,550
in your own data center and also in a plastic container service.

91
00:08:06,040 --> 00:08:11,860
So you do just need to be aware of the different ways of setting up x ray depending where you are running

92
00:08:11,860 --> 00:08:17,500
your application and for elastic container service in particular you need to know that you have to run

93
00:08:17,560 --> 00:08:24,190
the x ray daemon on its own Docker image running alongside your application because of course with Docker

94
00:08:24,310 --> 00:08:31,600
and with a micro services based architecture a micro service generally takes care of one task only and

95
00:08:31,600 --> 00:08:37,840
you wouldn't expect a docker container to be running more than one micro service so the x ray daemon

96
00:08:37,900 --> 00:08:44,480
runs within its own Docker image running alongside your application and when it comes to configuring

97
00:08:44,480 --> 00:08:46,710
x ray you're going to need three things.

98
00:08:46,730 --> 00:08:49,790
So first of all you need the x ray SDK.

99
00:08:50,180 --> 00:08:53,450
You also need the x ray Daemon to be running on your system.

100
00:08:53,450 --> 00:08:58,670
So either on your easy to instance or you're on premises host and then the last step is that you need

101
00:08:58,670 --> 00:09:05,360
to instrument your application using the x ray SDK to configure your application to send the required

102
00:09:05,420 --> 00:09:06,990
data into x ray.

103
00:09:07,070 --> 00:09:14,980
For example you might want to send data about incoming or outgoing HDTV requests to and from your application.

104
00:09:14,990 --> 00:09:22,670
And finally remember that you can record application specific information in the form of key value pairs

105
00:09:22,940 --> 00:09:26,920
which you define for example for a tic tac toe game.

106
00:09:26,990 --> 00:09:34,980
You might want to record the game name or the game I.D. and its annotations which allows you to do that.

107
00:09:34,990 --> 00:09:41,740
So just remember that name is called annotations and it allows you to add user defined key value pairs

108
00:09:41,950 --> 00:09:49,240
to your x ray data which in turn allows you to filter index and search within x ray so it allows you

109
00:09:49,240 --> 00:09:51,910
to group x ray results together.

110
00:09:51,910 --> 00:09:57,790
And so in this example it would allow you to group the data based on the game name or the game I.D.

111
00:09:59,830 --> 00:10:03,320
and finally moving on to elastic beanstalk and docker.

112
00:10:03,400 --> 00:10:09,730
So when you're using elastic beanstalk you can deploy your docker container to a single easy to instance

113
00:10:10,210 --> 00:10:16,870
and you can also deploy multiple docker containers to an elastic container service cluster and Elastic

114
00:10:16,870 --> 00:10:20,370
Beanstalk will handle all of the infrastructure for you.

115
00:10:20,440 --> 00:10:27,190
And if you remember in the lab all we had to do was upload our code and Elastic Beanstalk took care

116
00:10:27,190 --> 00:10:31,470
of provisioning and easy to instance for our code to run on.

117
00:10:31,720 --> 00:10:38,740
So to deploy a docker application just upload your code bundle to Elastic Beanstalk and when you want

118
00:10:38,740 --> 00:10:45,940
to upgrade your application to a new version it's just one easy step in the console to upload and deploy

119
00:10:45,970 --> 00:10:51,150
your new version and code can be uploaded directly from your local machine.

120
00:10:51,280 --> 00:10:59,110
As we did in the lab or you can also supply the name of a public S3 bucket containing your code bundle

121
00:10:59,140 --> 00:11:00,670
as well.

122
00:11:00,670 --> 00:11:04,260
And finally you can also store your code in code commit.

123
00:11:04,390 --> 00:11:10,750
But if you do that you must administer your elastic beanstalk environment using the Elastic Beanstalk

124
00:11:10,810 --> 00:11:12,640
command line interface.

125
00:11:12,640 --> 00:11:17,530
And don't worry too much about the Elastic Beanstalk CLIA because they're not going to test you on that

126
00:11:17,530 --> 00:11:19,090
in the exam.

127
00:11:19,090 --> 00:11:25,330
The important thing to note is that code commit integrates with Elastic Beanstalk and you can actually

128
00:11:25,330 --> 00:11:33,130
store your code there as well as on your local machine and in a public S3 bucket so that is the end

129
00:11:33,130 --> 00:11:37,490
of this lecture and is also at the end of this section of the course.

130
00:11:37,510 --> 00:11:43,060
So if you have any questions or if you go and take the exam and you see any topics which we haven't

131
00:11:43,060 --> 00:11:49,120
covered within the course please do let us know in the course forum so that we can update the course

132
00:11:49,210 --> 00:11:51,610
and make it the best it can be.

133
00:11:51,610 --> 00:11:55,320
So with that said thank you very much and we'll see you in the next lecture.
